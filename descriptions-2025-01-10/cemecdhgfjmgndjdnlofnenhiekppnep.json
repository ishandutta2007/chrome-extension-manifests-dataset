{
  "name": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "PseudoLocalizer"
  },
  "short": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "PseudoLocalize an HTML web page."
  },
  "long": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Update includes many bug fixes as well as improved padding now suing Japanese numerals.  \n\nSource code now available in github (https://github.com/eirikRude/pseudolocalizer)\n\nPseudolocalization is an important tool for the localization and internationalization engineer.  The goal of pseudolocalization is to provide an interface that is still usable while highlighting some of the common issues that appear when an application is localized.\n\nSome of the areas pseudolocalization attempts to test are:\n●Text expansion\n●●A common rule of thumb is that English text can be expected to grow around 30% when translated.  This is of course a general rule.  To test this a Pseudolocalization utility will pad text with expansion characters on each side.  For example: “test” -> “[1[Test]1]”\n\n●High value characters\n●●The first 256 characters are the same in both many ASCII and Unicode.  An incorrectly encoded page will not show an error when the text is only English, however after the content has been localized issues can show up.  A Pseudolocalization library will convert low value characters to high value accented characters that are still recognizable.  For example: “Z” -> “Ƶ” and “Pseudo Localization Rocks!” becomes “Ƥᶊëữďѻ Ĺѻčąľἳȥąțἳѻņ ȑѻčķᶊ!”\n\n●Bi-Directional text\n●●Some of the biggest challenges in right to left languages like Arabic or Hebrew arise because of the bi-directional nature of these scripts.  There are 3 types of Unicode characters, weak, strong, and neutral.  Strong characters have an inherent directionality.  An example of this is English “A” that contains a left-to-right directionality and Hebrew “א” contains a right-to-left directionality.  Neutral characters are direction neutral.  An example is “=” or “+.”  The third class are the most problematic.  Weak characters inherit their directionality from their neighbors.  Characters like “(“ or “)” are examples of this class.  When weak characters occur in the border between right-to-left and –left-to-right text they often display incorrectly.    Addressing this issue usually requires additional markup on the page to give these elements the correct directionality.\n\n----\nLimitations:\nPseudolocalization is usually performed as a part of the localization process on extracted resource files.  These are then incorporated into the application at build time or through a mechanism at run time.  The goal of this extension is to provide a quick and easy way to test basic pseudolocalization on a page earlier in the process with fewer requirements.  It is not designed to replace pseudolocalization of resource files.  It should be considered another tool to broaden coverage.\n\nA common localizability bug uncovered by pseudolocalization of resource files is concatenation of text.  This extension will not assist in detect concatenation as the pseudolocalization occurs on the rendered text post concatenation.\n\nThe extension works on HTML pages only.  The directionality setting changes the body dir attribute only.  It will not modify directionality specified in CSS or on HTML tags besides <body>.  This may be enhanced in a future version."
  }
}