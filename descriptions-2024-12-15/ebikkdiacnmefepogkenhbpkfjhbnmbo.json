{
  "name": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Local LLM Helper"
  },
  "short": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Interact with your local LLM server directly from your browser."
  },
  "long": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Local LLM Helper: Your Browser's Gateway to Private AI\n\nUnlock the power of large language models right from your browser, with complete privacy and control. Local LLM Helper is a Chrome extension that seamlessly connects your browsing experience to your personal AI server, allowing you to harness advanced language processing capabilities without relying on cloud-based services.\n\nKey Features:\n\n1. Private and Secure:\n   - Connect to your own local LLM server, ensuring your data never leaves your control.\n   - Perfect for handling sensitive information or maintaining strict data privacy.\n\n2. Versatile Text Processing:\n   - Summarize lengthy articles or documents with a single click.\n   - Transform casual text into professional-grade content.\n   - Generate actionable items from meeting notes or project descriptions.\n   - Generate Twitter threads or hot takes.\n   - Craft custom prompts for specialized tasks.\n\n3. Seamless Integration:\n   - Works on MOST webpages, allowing you to process text without leaving your current tab.\n   - Simple select-and-click interface for effortless use.\n\n4. Customizable:\n   - Compatible with various local LLM servers, including Ollama and LM Studio.\n   - Easily switch between different AI models to suit your specific needs.\n\n5. Resource-Efficient:\n   - Leverage your local hardware, making it ideal for users with powerful GPUs or specialized AI hardware.\n\nHow It Works:\n\n1. Select text on any webpage.\n2. Choose a processing option (summarize, professionalize, generate action items, or custom prompt).\n3. Click \"Transform\" and watch as your local AI processes the text.\n4. View the results directly in your browser, formatted for easy reading.\n\nSetup and Compatibility:\n\n- Requires a local LLM server (e.g., Ollama, LM Studio) running on your machine or local network.\n- Easy configuration through the extension's options page.\n- Compatible with a wide range of LLM models, depending on your local setup.\n\nPrivacy and Security:\n\nLocal LLM Helper is designed with privacy as a top priority. Unlike cloud-based AI services, all processing occurs on your local machine or network. This means:\n\n- No data is sent to external servers.\n- Complete control over which models and data are used.\n- Ideal for businesses and individuals handling sensitive or confidential information.\n\nUse Cases:\n\n1. Researchers and Students:\n   - Quickly summarize academic papers or lengthy articles.\n   - Generate study notes or key points from textbooks.\n\n2. Professionals:\n   - Transform rough notes into polished reports.\n   - Create action items from meeting minutes.\n   - Improve email communication by enhancing casual drafts.\n\n3. Content Creators:\n   - Generate ideas or outlines from existing content.\n   - Refine and polish draft content.\n\n4. Developers:\n   - Summarize documentation or code comments.\n   - Generate pseudo-code from natural language descriptions.\n\n5. Legal Professionals:\n   - Summarize case law or legal documents.\n   - Extract key points from contracts or agreements.\n\n6. Healthcare Professionals:\n   - Summarize medical literature while maintaining patient privacy.\n   - Generate patient-friendly explanations from technical medical text.\n\nCustomization and Flexibility:\n\nLocal LLM Helper is designed to be highly adaptable to your specific needs:\n\n- Custom Prompts: Create your own prompts for specialized tasks unique to your field or requirements.\n- Model Selection: Switch between different AI models to optimize for speed, accuracy, or specific domain knowledge.\n- Server Configuration: Easily update server settings to connect to different local LLM setups.\n\nPerformance and Efficiency:\n\nBy leveraging your local hardware, Local LLM Helper can offer:\n\n- Faster processing times, especially for users with powerful GPUs.\n- Ability to work offline, perfect for travel or areas with limited internet connectivity.\n- No usage limits or API costs associated with cloud-based services.\n\nGetting Started:\n\n1. Install the Local LLM Helper extension from the Chrome Web Store.\n2. Set up a local LLM server (like Ollama or LM Studio) on your machine or local network.\n3. Configure the extension with your server's address and preferred model.\n4. Start transforming text on any webpage with the power of AI!\n\nTroubleshooting and Support:\n\nThe extension includes a comprehensive FAQ section covering common setup issues and best practices, including:\n\n- Configuring CORS settings for your local server.\n- Optimizing performance for different hardware setups.\n- Troubleshooting connection issues.\n\nFor additional support, visit our GitHub repository for documentation, issue tracking, and community discussions.\n\nFuture Development:\n\nWe're committed to continually improving Local LLM Helper. Planned features include:\n\n- Support for more local LLM server types.\n- Additional text processing options.\n- Integration with local vector databases for enhanced context-aware processing.\n- Collaborative features for team environments.\n\nEmbrace the future of private, powerful, and personalized AI assistance with Local LLM Helper. Transform your browsing experience while keeping your data under your control. Download now and unlock the potential of your personal AI right in your browser!"
  }
}