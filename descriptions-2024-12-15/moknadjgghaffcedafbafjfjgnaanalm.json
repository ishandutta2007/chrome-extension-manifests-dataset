{
  "name": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Semantic Search"
  },
  "short": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Search webpages or entered text for the answers you need."
  },
  "long": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "If you've ever been to pages like Wikipedia, you know finding simple answers in the vast amounts of text can be a pain. The semantic search extension makes finding answers to your questions easy and painless. This extension gathers the text from your current webpage, takes a question as input from you, the user, and passes it into a natural language processing model to answer your question using artificial intelligence.\n\nEven if you don't word your question exactly as the answer appears on the website, you don't need to worry because the  NLP model can still answer your hardest questions accurately.\n\n\n\nHow to use:\n•  This extension has two tabs, \"Scan Webpage\" and \"Manually Enter.\" \n•  To parse the text of your current tab for an answer, use the \"Scan Webpage\" tab and simply ask the question you want answered. \n•  If you want to parse a specific block of text for an answer, you can use the \"Manually Enter\" tab by pasting the text block you want scanned into the \"Text to Scan\" field, and your question into the \"Question\" field.\n\n\nUpdates:\n•  1.2.0: The extension has switched to a new backend service for model inference. It now uses banana.dev and a custom-built model inference pipeline. The extension performed slower in testing, but the answers and server reliability were greatly improved.\n•  1.3.0: The extension has switched to using ChatGPT for question answering. Due to now using OpenAI's servers, the maximum context length is 11,000 words. Also, webpages cannot be chunked into smaller pieces automatically due to ChatGPT not reliably giving a confidence score along with its answer. Despite this, model inference is now faster than ever and the answers generated are much more reliable.\n•  1.3.1: Minor big fixes.\n•  1.3.2: Added support for searching text in Google Docs.\n•  1.3.3: Made all extension requests route through a Cloudflare Worker server to act as a proxy.\n\n\nFeedback:\nlukesutor@gmail.com\n\nWebsite:\nlukesutor.com"
  }
}