{
  "name": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Robots.txt Checker - cmlabs SEO Tools"
  },
  "short": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Robots.txt Checker is an essential tool designed to ensure the efficiency, accuracy, and validity of a website's robots.txt file."
  },
  "long": {
    "am,ar,bg,bn,ca,cs,da,de,el,en,en_AU,en_GB,en_US,es,es_419,et,fa,fi,fil,fr,gu,he,hi,hr,hu,id,it,ja,kn,ko,lt,lv,ml,mr,ms,nl,no,pl,pt_BR,pt_PT,ro,ru,sk,sl,sr,sv,sw,ta,te,th,tr,uk,vi,zh_CN,zh_TW": "Robots.txt Checker by cmlabs is your ultimate tool for managing the essential aspects of your website's robots.txt file. Tailored for website owners and developers alike, this tool simplifies the often complex tasks associated with maintaining a healthy robots.txt configuration.\n\nWith just a few clicks, you can ensure that your directives are correctly set up to guide search engine crawlers effectively. This tool can swiftly verify whether specific URLs are being appropriately blocked or allowed by your robots.txt directives.  Letâ€™s take control of your website's indexing directives. Download and try now!\n\nFeatures & Benefits\n\n- This tool is available for free.\n- Checking Blocked URLs: Help you verify whether specific URLs on your website are blocked by the robots.txt file.\n- Identification of Blocking Statements: These statements are rules containing instructions for search engines not to index or access specific pages or directories on a website.\n- Checking Sitemap Files: The sitemap.xml file is an essential document to enhance your site's visibility in search engines.\n\nHow to Use\n\n1. Open the Robots.txt Checker\nYou can proceed by choosing the Robots.txt Checker tool to start analyzing URLs and checking the robots.txt or sitemap.xml files within them.\n\n2. Enter the URL\nTo initiate the review process, simply enter the URL, as shown in the example in the blue box at the top of the tool's page. For a smooth review process, make sure the URL you enter follows the format: https://www.example.com.\n\n3. Start the Review Process\nAfter entering the URL, you'll see several buttons, including \"Check Source\", selecting the bot type, and checking the URL through the \"Check URL\" button. Please note that you can only review URLs up to 5 times within 1 hour.\n\n4. Analyze the Data\nOnce the review process is complete, you'll be presented with results that show several pieces of information, including:\n\n- Website URL\n- Host\n- Sitemap\n- Robots.txt File\n\nHelp & Support\n\nWe value your feedback! If you have any suggestions for improving Robots.txt Checker or encounter any issues while using the tool, please don't hesitate to let us know. Our support team is here to help. Reach us by email at:\n\nmarketing@cmlabs.co \ndev@cmlabs.co"
  }
}